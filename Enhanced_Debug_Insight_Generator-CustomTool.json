{
  "name": "Enhanced_Debug_Insight_Generator",
  "description": "End-of-flow log harvester + AI fixer. Pulls Render logs + Flowise chatflow definition + conversation history, dedupes recurring errors, sends bundle + context to Claude for production-grade full-block replacements. Stores fixes under a persistent disk path and optionally self-loops after a configurable delay.",
  "color": "linear-gradient(rgb(27,159,95), rgb(166,49,34))",
  "iconSrc": "https://img.icons8.com/fluency/48/bug.png",
  "schema": "[{\"id\":0,\"property\":\"analysis_mode\",\"type\":\"string\",\"description\":\"Log analysis mode: 'recent','window','full'\",\"required\":false},{\"id\":1,\"property\":\"time_range_minutes\",\"type\":\"number\",\"description\":\"Lookback window in minutes for logs (default 60).\",\"required\":false},{\"id\":2,\"property\":\"focus_services\",\"type\":\"string\",\"description\":\"Comma list of services to focus (market_intel, portfolio, arbitrage, trade_exec, telegram, multi_ai, journal, controller).\",\"required\":false},{\"id\":3,\"property\":\"include_project_context\",\"type\":\"boolean\",\"description\":\"If true, also attach project context for AI (tools & main agent).\",\"required\":false},{\"id\":4,\"property\":\"project_context_url\",\"type\":\"string\",\"description\":\"Optional URL to fetch zipped/JSON project context.\",\"required\":false},{\"id\":5,\"property\":\"dedupe_window_minutes\",\"type\":\"number\",\"description\":\"Do not re-ask AI for repeating errors seen within this window (default 120).\",\"required\":false},{\"id\":6,\"property\":\"enable_loop\",\"type\":\"boolean\",\"description\":\"If true, wait then relaunch the flow (self-loop).\",\"required\":false},{\"id\":7,\"property\":\"loop_delay_minutes\",\"type\":\"number\",\"description\":\"Delay before relaunch. Default 5. Can be 1,5,15,30 etc.\",\"required\":false},{\"id\":8,\"property\":\"restart_payload\",\"type\":\"string\",\"description\":\"Optional JSON to send when re-triggering the flow.\",\"required\":false},{\"id\":9,\"property\":\"use_render_logs\",\"type\":\"boolean\",\"description\":\"Fetch logs from Render Public API if credentials present.\",\"required\":false},{\"id\":10,\"property\":\"render_service_id\",\"type\":\"string\",\"description\":\"Override Render Service ID. Otherwise uses $vars.RENDER_SERVICE_ID.\",\"required\":false},{\"id\":11,\"property\":\"chatflow_id\",\"type\":\"string\",\"description\":\"Chatflow ID to fetch definition & conversation for.\",\"required\":false},{\"id\":12,\"property\":\"session_id\",\"type\":\"string\",\"description\":\"Conversation sessionId filter (optional).\",\"required\":false},{\"id\":13,\"property\":\"persist_dir\",\"type\":\"string\",\"description\":\"Absolute directory to persist outputs. Defaults to $PERSIST_DIR or /opt/render/.flowise/ai_fixes on Render.\",\"required\":false}]",
  "func": "\nconst fetch = require('node-fetch');\nconst crypto = require('crypto');\nconst fs = require('fs').promises;\nconst path = require('path');\n\nasync function toolMain(opts) {\n  const startedAt = Date.now();\n  const nowIso = new Date().toISOString();\n  const runId = 'dbg_'+Date.now().toString(36)+'_'+Math.random().toString(36).slice(2,8);\n\n  const {\n    analysis_mode,\n    time_range_minutes,\n    focus_services,\n    include_project_context,\n    project_context_url,\n    dedupe_window_minutes,\n    enable_loop,\n    loop_delay_minutes,\n    restart_payload,\n    use_render_logs,\n    render_service_id,\n    chatflow_id,\n    session_id,\n    persist_dir\n  } = opts || {};\n\n  const mode = (analysis_mode || 'recent').toLowerCase();\n  const lookbackMin = Math.max(1, parseInt(time_range_minutes || 60));\n  const focus = (focus_services || 'all').split(',').map(s => s.trim().toLowerCase());\n  const deDupMin = Math.max(5, parseInt(dedupe_window_minutes || 120));\n  const loopEnabled = !!enable_loop;\n  const loopDelayMin = Math.max(1, parseInt(loop_delay_minutes || 5));\n  const useRender = (typeof use_render_logs !== 'undefined') ? !!use_render_logs : true;\n\n  function getVar(name, fallback=null) {\n    try { if (typeof $vars !== 'undefined' && $vars[name] != null) return $vars[name]; } catch(e) {}\n    try { if (process && process.env && process.env[name] != null) return process.env[name]; } catch(e) {}\n    return fallback;\n  }\n\n  const FLOWISE_BASE = (getVar('FLOWISE_BASE_URL') || 'http://localhost:3000').replace(/\\/+$/,'') + '/api/v1';\n  const FLOWISE_SECRET = getVar('FLOWISE_SECRET_KEY', null); // used for Bearer on admin endpoints in self-hosted envs\n  const WORKSPACE_ID = getVar('FLOWISE_WORKSPACE_ID', 'default-workspace');\n\n  const CLAUDE_KEY  = getVar('ANTHROPIC_API_KEY', getVar('CLAUDE_API_KEY', null));\n  const CLAUDE_MODEL = getVar('CLAUDE_MODEL', 'claude-3-5-sonnet-latest');\n\n  const RENDER_KEY = getVar('RENDER_API_KEY', null);\n  const RENDER_SERVICE_ID = render_service_id || getVar('RENDER_SERVICE_ID', null);\n\n  // ===== persistence dir (use Render persistent disk if available) =====\n  // Prefer explicit persist_dir input, else $PERSIST_DIR, else Render doc default '/opt/render/.flowise/ai_fixes'\n  const basePersistDir = persist_dir || getVar('PERSIST_DIR', '/opt/render/.flowise/ai_fixes');\n  async function ensureDir(p) { try { await fs.mkdir(p, { recursive: true }); } catch (_) {} }\n  async function readJSON(p, def=null) { try { const s = await fs.readFile(p,'utf8'); return JSON.parse(s); } catch(e){ return def; } }\n  async function writeJSON(p, obj) { await fs.writeFile(p, JSON.stringify(obj,null,2), 'utf8'); }\n\n  const registryPath = path.posix.join(basePersistDir, 'registry.json');\n\n  // ===== helpers =====\n  function h16(s){ return crypto.createHash('sha256').update(s).digest('hex').slice(0,16); }\n  function authHeaders() {\n    const h = { 'Content-Type':'application/json' };\n    if (FLOWISE_SECRET) h['Authorization'] = `Bearer ${FLOWISE_SECRET}`;\n    return h;\n  }\n\n  // ===== logs: Render =====\n  async function fetchRenderLogsWindow(mins) {\n    if (!useRender || !RENDER_KEY || !RENDER_SERVICE_ID) return [];\n    const end = new Date();\n    const start = new Date(end.getTime() - mins*60*1000);\n    const url = new URL('https://api.render.com/v1/logs');\n    url.searchParams.set('serviceId', RENDER_SERVICE_ID);\n    url.searchParams.set('startTime', start.toISOString());\n    url.searchParams.set('endTime', end.toISOString());\n    url.searchParams.set('limit', '1000');\n    const headers = { 'Authorization': `Bearer ${RENDER_KEY}` };\n    const out = [];\n    try {\n      let nextUrl = url.toString();\n      for (let page=0; page<5; page++) {\n        const r = await fetch(nextUrl, { headers });\n        if (!r.ok) break;\n        const j = await r.json();\n        const lines = (j && j.logs) ? j.logs : [];\n        for (const line of lines) {\n          out.push({ timestamp: line.timestamp || new Date().toISOString(), level: line.level || 'info', message: line.message || '', source: 'render' });\n        }\n        if (j.hasMore && j.nextStartTime && j.nextEndTime) {\n          const u = new URL('https://api.render.com/v1/logs');\n          u.searchParams.set('serviceId', RENDER_SERVICE_ID);\n          u.searchParams.set('startTime', j.nextStartTime);\n          u.searchParams.set('endTime', j.nextEndTime);\n          u.searchParams.set('limit', '1000');\n          nextUrl = u.toString();\n        } else break;\n      }\n    } catch(e) {}\n    return out;\n  }\n\n  // ===== Flowise: chatflow definition & conversation history =====\n  async function listChatflows() {\n    try {\n      const r = await fetch(`${FLOWISE_BASE}/chatflows`, { headers: authHeaders() });\n      if (!r.ok) return [];\n      const j = await r.json();\n      return Array.isArray(j)? j: [];\n    } catch(e){ return []; }\n  }\n  async function fetchChatflowDef(id) {\n    try {\n      const r = await fetch(`${FLOWISE_BASE}/chatflows/${id}`, { headers: authHeaders() });\n      if (!r.ok) return null;\n      return await r.json();\n    } catch(e){ return null; }\n  }\n  async function fetchChatMessages(id, startIso, endIso, sessionId) {\n    try {\n      const u = new URL(`${FLOWISE_BASE}/chatmessage/${id}`);\n      if (sessionId) u.searchParams.set('sessionId', sessionId);\n      u.searchParams.set('startDate', startIso);\n      u.searchParams.set('endDate', endIso);\n      u.searchParams.set('order','ASC');\n      const r = await fetch(u.toString(), { headers: authHeaders() });\n      if (!r.ok) return [];\n      return await r.json();\n    } catch(e){ return []; }\n  }\n\n  // ===== collection =====\n  async function collectEverything() {\n    const end = new Date();\n    const start = new Date(end.getTime() - lookbackMin*60*1000);\n    const [renderLogs, flows] = await Promise.all([\n      fetchRenderLogsWindow(lookbackMin),\n      listChatflows()\n    ]);\n    let activeChatflowId = chatflow_id || (flows[0]?.id || null);\n    let chatflowDef = null;\n    let chatMsgs = [];\n    if (activeChatflowId) {\n      [chatflowDef, chatMsgs] = await Promise.all([\n        fetchChatflowDef(activeChatflowId),\n        fetchChatMessages(activeChatflowId, start.toISOString(), end.toISOString(), session_id || null)\n      ]);\n    }\n    return { renderLogs, chatflowDef, chatMsgs, window:{ start: start.toISOString(), end: end.toISOString() } };\n  }\n\n  function filterByServices(logs) {\n    if (!logs || focus.includes('all')) return logs;\n    return logs.filter(l => {\n      const msg = ((l.message||'') + ' ' + (l.service||'') + ' ' + (l.category||'')).toLowerCase();\n      return focus.some(f => msg.includes(f));\n    });\n  }\n\n  function extractErrorSignatures(mergedLogs, chatMsgs) {\n    const errLines = [];\n    for (const l of mergedLogs) {\n      const m = (l.message||'').toLowerCase();\n      if (m.includes('error') || m.includes('exception') || m.includes('failed')) errLines.push(l.message||'');\n    }\n    for (const m of (chatMsgs||[])) {\n      const t = (m?.content || '').toLowerCase();\n      if (t.includes('error') || t.includes('exception') || t.includes('failed')) errLines.push(m.content || '');\n    }\n    const counts = {};\n    for (const s of errLines) {\n      const key = s.split('\\n')[0].slice(0,300);\n      counts[key] = (counts[key]||0)+1;\n    }\n    const top = Object.entries(counts).sort((a,b)=>b[1]-a[1]).slice(0,10).map(([m,c])=>m);\n    return top.map(m => ({ message: m, signature: h16(m) }));\n  }\n\n  async function loadRegistry() { return await readJSON(registryPath, { pending:{}, history:[] }); }\n\n  async function recordPending(reg, sigList, bundleFile) {\n    const now = new Date().toISOString();\n    for (const s of sigList) {\n      reg.pending[s.signature] = { error_message: s.message, fix_file: path.posix.basename(bundleFile), created_at: now, status: 'pending' };\n    }\n    reg.history.push({ run_id: runId, at: now, file: path.posix.basename(bundleFile) });\n    await writeJSON(registryPath, reg);\n  }\n\n  function shouldSkip(signature, reg, windowMin) {\n    const rec = reg.pending[signature];\n    if (!rec || !rec.created_at) return false;\n    const ageMs = Date.now() - new Date(rec.created_at).getTime();\n    return ageMs < windowMin*60*1000;\n  }\n\n  async function buildContextBundle(collected) {\n    const ctx = {\n      summary: {\n        production: true,\n        constraints: ['No simplifications','No hardcoded mock data','Do not remove features','Fix root cause with production-safe code'],\n        lookback_minutes: lookbackMin\n      },\n      chatflow: collected.chatflowDef || null,\n      conversation: (collected.chatMsgs || []).slice(0, 300), // cap messages count\n      window: collected.window\n    };\n    try {\n      if (include_project_context && project_context_url) {\n        const r = await fetch(project_context_url, { timeout: 8000 });\n        if (r.ok) ctx.project_context_blob = (await r.text()).slice(0, 750000);\n      }\n    } catch(e){}\n    return ctx;\n  }\n\n  async function askClaudeForFixes(errorSigs, mergedLogs, ctx) {\n    if (!CLAUDE_KEY) return { skipped:true, reason:'Missing Claude API key' };\n    const shortLogs = mergedLogs.slice(0,200).map(l => (l.timestamp||'')+' '+(l.level||'')+' '+(l.message||'')).join('\\n');\n    const userContent = [\n      { type:'text', text:\n`You are the CTO fixer for a Flowise-based production AI crypto trading system.\nInput: recent Render logs, Flowise chatflow definition, conversation excerpts, optional project context.\nTask:\n1) Identify root cause for each error signature.\n2) Propose production-grade code replacements (full function or block). No mock data. Do not remove features.\n3) Return STRICT JSON with schema:\n{\"updates\":[{\"target\":\"ToolName or File\",\"location_hint\":\"function or path\",\"language\":\"javascript\",\"replacement_code\":\"/* full function or block */\"}],\n \"tests\":[\"CLI or API steps we can run\"],\n \"notes\":\"short rationale & risk warnings\"}\nNo markdown, no prose.`\n      },\n      { type:'text', text:`Error signatures: ${errorSigs.map(e=>e.message).join(' | ')}` },\n      { type:'text', text:`Logs (truncated):\\n${shortLogs}` },\n      { type:'text', text:`Context keys: ${Object.keys(ctx||{}).join(', ')}` }\n    ];\n\n    const body = {\n      model: CLAUDE_MODEL,\n      max_tokens: 3000,\n      temperature: 0.1,\n      system: \"Return JSON per schema. No prose. No placeholders. Production-grade.\",\n      messages: [{ role:'user', content: userContent }]\n    };\n\n    const res = await fetch('https://api.anthropic.com/v1/messages', {\n      method:'POST',\n      headers: {\n        'content-type':'application/json',\n        'x-api-key': CLAUDE_KEY,\n        'anthropic-version':'2023-06-01'\n      },\n      body: JSON.stringify(body)\n    });\n    if (!res.ok) {\n      const txt = await res.text();\n      return { error:`Claude API ${res.status}`, detail: txt };\n    }\n    const j = await res.json();\n    const txt = (j && j.content && j.content[0] && j.content[0].text) ? j.content[0].text : '';\n    let parsed = null;\n    try { parsed = JSON.parse(txt); } catch(e) { parsed = { raw: txt, parse_error: true }; }\n    return { ok:true, model: CLAUDE_MODEL, output: parsed, raw: txt };\n  }\n\n  async function persistBundle(baseDir, content) {\n    await ensureDir(baseDir);\n    const filePath = path.posix.join(baseDir, `${runId}.json`);\n    await writeJSON(filePath, content);\n    return filePath;\n  }\n\n  async function reTriggerAfterDelay(ms) {\n    await new Promise(res => setTimeout(res, ms));\n    if (!FLOWISE_SECRET) return { skipped:true, reason:'Missing FLOWISE_SECRET_KEY' };\n    const payload = restart_payload ? JSON.parse(restart_payload) : { service:'Master_System_Controller', function:'autonomous_cycle', parameters:{} };\n    const url = `${FLOWISE_BASE.replace('/api/v1','')}/api/v1/prediction/${WORKSPACE_ID}`;\n    const res = await fetch(url, { method:'POST', headers: authHeaders(), body: JSON.stringify({ question: JSON.stringify(payload) }) });\n    if (!res.ok) return { error:`Restart call failed ${res.status}` };\n    const j = await res.json();\n    return { ok:true, response: j };\n  }\n\n  // === MAIN ===\n  await ensureDir(basePersistDir);\n  const collected = await collectEverything();\n  const mergedLogs = filterByServices(collected.renderLogs);\n  const sigs = extractErrorSignatures(mergedLogs, collected.chatMsgs);\n\n  const reg = await loadRegistry();\n  const toAsk = sigs.filter(s => !shouldSkip(s.signature, reg, deDupMin));\n\n  let claudeOut = { skipped:true, reason:'No new signatures' };\n  if (toAsk.length > 0) {\n    const ctx = await buildContextBundle(collected);\n    claudeOut = await askClaudeForFixes(toAsk, mergedLogs, ctx);\n    const bundle = { run_id: runId, created_at: nowIso, window: collected.window, chatflow_id: (collected.chatflowDef && collected.chatflowDef.id) || null, signatures: toAsk, claude: claudeOut };\n    const savePath = await persistBundle(basePersistDir, bundle);\n    await recordPending(reg, toAsk, savePath);\n  }\n\n  const durationMs = Date.now() - startedAt;\n  const loopWaitMs = Math.max(0, loopDelayMin*60*1000 - durationMs);\n  let loopResult = null;\n  if (loopEnabled) loopResult = await reTriggerAfterDelay(loopWaitMs);\n\n  return {\n    success: true,\n    run_id: runId,\n    persist_dir: basePersistDir,\n    started_at: new Date(startedAt).toISOString(),\n    finished_at: new Date().toISOString(),\n    analysis: { mode, lookback_minutes: lookbackMin, render_logs: collected.renderLogs.length, chat_messages: (collected.chatMsgs||[]).length, signatures: sigs },\n    loop: { enabled: loopEnabled, delay_minutes: loopDelayMin, waited_ms: loopEnabled ? loopWaitMs : 0, result: loopResult },\n    tip: \"Attach a Render Persistent Disk and set $PERSIST_DIR to its mount path + '/ai_fixes' to persist across deploys.\"\n  };\n}\n\nreturn await toolMain({\n  analysis_mode: (typeof $analysis_mode !== 'undefined') ? $analysis_mode : null,\n  time_range_minutes: (typeof $time_range_minutes !== 'undefined') ? $time_range_minutes : null,\n  focus_services: (typeof $focus_services !== 'undefined') ? $focus_services : null,\n  include_project_context: (typeof $include_project_context !== 'undefined') ? $include_project_context : null,\n  project_context_url: (typeof $project_context_url !== 'undefined') ? $project_context_url : null,\n  dedupe_window_minutes: (typeof $dedupe_window_minutes !== 'undefined') ? $dedupe_window_minutes : null,\n  enable_loop: (typeof $enable_loop !== 'undefined') ? $enable_loop : null,\n  loop_delay_minutes: (typeof $loop_delay_minutes !== 'undefined') ? $loop_delay_minutes : null,\n  restart_payload: (typeof $restart_payload !== 'undefined') ? $restart_payload : null,\n  use_render_logs: (typeof $use_render_logs !== 'undefined') ? $use_render_logs : null,\n  render_service_id: (typeof $render_service_id !== 'undefined') ? $render_service_id : null,\n  chatflow_id: (typeof $chatflow_id !== 'undefined') ? $chatflow_id : null,\n  session_id: (typeof $session_id !== 'undefined') ? $session_id : null,\n  persist_dir: (typeof $persist_dir !== 'undefined') ? $persist_dir : null\n});\n",
  "workspaceId": "9b1b9829-f76f-472f-867f-4bac66fb62c0"
}